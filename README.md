
# Ex-01_DS_Data_Cleansing
## NAME: MUKESH.B
## REG NO: 212223230128


## AIM
To read the given data and perform data cleaning and save the cleaned data to a file. 

# Explanation
Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect ,incompleted , irrelevant , duplicated or improperly formatted. 
Data cleaning is not simply about erasing data ,but rather finding a way to maximize datasets accuracy without necessarily deleting the information. 

# ALGORITHM
### STEP 1
Read the given Data
### STEP 2
Get the information about the data
### STEP 3
Remove the null values from the data
### STEP 4
Save the Clean data to the file

# CODE and OUTPUT

![Screenshot 2025-03-04 105135](https://github.com/user-attachments/assets/a3db6a02-4c20-45a7-9ba7-90a3c18ea6d6)

![Screenshot 2025-03-04 105150](https://github.com/user-attachments/assets/4c67c79e-c9eb-45f5-9a73-eeb7bd1febf9)

![Screenshot 2025-03-04 105202](https://github.com/user-attachments/assets/ce0005c4-b0ab-4176-93b2-304e6efe0acb)

![Screenshot 2025-03-04 105225](https://github.com/user-attachments/assets/d55d9e98-c8df-4007-ba39-f5af2bc0594b)

![Screenshot 2025-03-04 105237](https://github.com/user-attachments/assets/abc93926-ec8b-4e29-a33a-4dd5256a50fb)

![Screenshot 2025-03-04 105247](https://github.com/user-attachments/assets/09cbf6b2-1126-48e8-84ff-968cd64c3420)

![Screenshot 2025-03-04 105259](https://github.com/user-attachments/assets/7f97e56a-f84c-4e9b-99a5-aacc976bae6c)

![Screenshot 2025-03-04 105310](https://github.com/user-attachments/assets/02983d7f-b0e6-4e4f-a8eb-e155e8d68ab4)

![Screenshot 2025-03-04 105318](https://github.com/user-attachments/assets/83f0e77a-a57f-489e-a2b1-277c0529f441)

![Screenshot 2025-03-04 105326](https://github.com/user-attachments/assets/b0c4eff3-2542-4304-b963-7d46c488beed)

![Screenshot 2025-03-04 105333](https://github.com/user-attachments/assets/286e2c81-b347-4723-bab4-bc490e25b6d3)

![Screenshot 2025-03-04 105347](https://github.com/user-attachments/assets/9976cca9-e379-4f1f-a36b-e5a3c06a670d)

![Screenshot 2025-03-04 105341](https://github.com/user-attachments/assets/9a7b47a4-a289-4566-9b96-40a52d6f6a74)

![Screenshot 2025-03-04 105359](https://github.com/user-attachments/assets/f62c77b1-f468-4696-8272-0df6703785da)

![Screenshot 2025-03-04 105406](https://github.com/user-attachments/assets/e4e00f80-09cf-405c-9e76-d718c1043f4f)

![Screenshot 2025-03-04 105411](https://github.com/user-attachments/assets/7181e7ac-a1db-4c34-bc91-a50d8c27d8de)

![Screenshot 2025-03-04 105418](https://github.com/user-attachments/assets/ab219fc7-946e-4e27-a611-a68b9873c55e)

![Screenshot 2025-03-04 105427](https://github.com/user-attachments/assets/cdaafb9c-6f86-4b2f-845b-396d9dc2553b)

![Screenshot 2025-03-04 105434](https://github.com/user-attachments/assets/6ee1256f-25a0-426b-85e8-84407e6e919d)


## RESULT:
Thus we have cleaned the data and removed the outliers by detection using IQR and Z-score method.

